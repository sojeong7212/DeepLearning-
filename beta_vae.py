# -*- coding: utf-8 -*-
"""beta_VAE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e1g1xIWygn13alXkpMcUmp2zvB-n8Z10

## **Beta-Variational Autoencoder (Beta-VAE)**

전통적인 오토인코더는 잠재 벡터 표현에 대한 유일한 제약이 잠재 벡터를 원본 이미지로 쉽게 디코딩할 수 있어야 한다는 것입니다. 그러나 이로 인해 비연속 및 연속되지 않은 잠재 공간 $Z$이 나타날 수 있습니다. 베타-바리에이션얼 오토인코더 (Beta-VAE)는 이러한 한계를 극복하기 위한 것입니다.

Beta-VAE는 전통적인 오토인코더와 다르게 입력을 잠재 벡터의 확률 분포로 매핑하고, 그 분포에서 잠재 벡터를 샘플링합니다. 이로써 잠재 벡터에 대한 더 견고한 디코더가 얻어집니다.

구체적으로, 입력 $x$를 결정론적으로 잠재 벡터 $z=e(x)$로 매핑하는 대신 Beta-VAE는 평균 벡터 $\mu_{z}(x)$와 분산 벡터 ${\sigma}^2_{z}(x)$로 매핑합니다. 이들은 대각선 가우시안 분포 $\mathscr{N}({\mu}_{z},{\sigma}^2_{z})$를 매개변수화합니다. 그런 다음, 잠재 벡터 $z$는 이 분포에서 샘플링됩니다. 이때 **베타** 하이퍼파라미터를 도입하여 $z \sim \mathscr{N}(\mu_z,{\sigma}^2_{z})$과 같이 정의됩니다.

Beta-VAE는 **베타** 값을 조절함으로써 재구성 품질과 잠재 공간의 해체성 간의 균형을 제어할 수 있으므로 의미 있는 표현을 학습하는 강력한 도구로 사용됩니다
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils
import torch.distributions as D
import torchvision
import numpy as np
import matplotlib.pyplot as plt

device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(device)

"""###**Set training parameters**

"""

batchsize = 128
nplot_test = 5
dim_x_list = [28, 28]
dim_x = dim_x_list[0] * dim_x_list[1]
traindata = torchvision.datasets.MNIST('./traindata',
                                       transform=torchvision.transforms.ToTensor(),
                                       train=True, download=True)
testdata = torchvision.datasets.MNIST('./testdata',
                                      transform=torchvision.transforms.ToTensor(),
                                      train=False, download=True)
traindataloader = torch.utils.data.DataLoader(traindata, batch_size=batchsize, shuffle=True)
testdataloader = torch.utils.data.DataLoader(testdata, batch_size=nplot_test, shuffle=True)

"""
### **Define the Beta-VAE Network**
The loss function for a Beta-VAE comprises two distinct components: **reconstruction loss** and **regularization loss** with the introduction of the **beta** hyperparameter.

*   **Reconstruction loss** (Binary Cross-Entropy):
$$-\mathbb{E}_{z \sim q_{\phi}(z|x)} \big[ \log{p_{\theta}(x|z)} \big]
\simeq - \sum_{x \in X_{data}} \Big(p(x) \cdot \log\big(p(\hat{x})\big) \Big)$$

*   **Regularization loss**:
$$
-\mathbb{KL}\Big( \mathscr{N}\big({\mu}_{z}(x), {\sigma}^2_{z}(x)\big) \parallel \mathscr{N}(0, 1) \Big)
= - \sum_{x \in X_{data}} \Big( {\sigma}^2_{z}(x) + ({\mu}_{z}(x))^2
- \frac{1}{2} \log \big({\sigma}^2_{z}(x)\big) - \frac{1}{2} \Big)
$$

Beta-VAE에서의 재구성 손실은 이항 교차 엔트로피 손실 또는 L2 손실로 구현할 수 있습니다. 또한, Beta-VAE는 베타 하이퍼파라미터를 도입하는데, 이것은 정규화 손실의 중요성을 조절하는 데 사용됩니다. 베타 값을 변화시킴으로써 Beta-VAE 모델에서 재구성과 정규화 간의 균형을 조절할 수 있습니다.


$$\mathscr{L}({\phi},{\theta}) =-\mathbb{E}_{q}\big[ \log{p_{\theta}(x|z)} \big]+ \beta \mathscr{KL} ({q}_{\theta}(z|x)∥{p}(z)) $$


        
Reference : '$\beta - VAE$: Learning Basic Visual Concepts with a Constrained Variational Framework'
MNIST dataset
"""

class BVAE(nn.Module):
  def __init__(self, **kwargs):
    super(BVAE, self).__init__()
    self.__dict__.update(kwargs)

    # Encoder
    self.dense1_enc = nn.Linear(self.dim_x, self.dim_h)
    self.dense2_enc = nn.Linear(self.dim_h, self.dim_h)
    self.dense_mu_enc = nn.Linear(self.dim_h, self.dim_z)
    self.dense_logvar_enc = nn.Linear(self.dim_h, self.dim_z)

    # Decoder
    self.dense1_dec = nn.Linear(self.dim_z, self.dim_h)
    self.dense2_dec = nn.Linear(self.dim_h, self.dim_h)
    self.dense3_dec = nn.Linear(self.dim_h, self.dim_x)

    self.relu = nn.ReLU()

    self.epsilon = D.Normal(0, 1)
    #self.epsilon.loc = self.epsilon.loc.cuda()   # hack to get sampling on the GPU
    #self.epsilon.scale = self.epsilon.scale.cuda()

  def encode(self, x):
    x = torch.flatten(x, start_dim=1)
    _h1 = self.relu(self.dense1_enc(x))
    _h2 = self.relu(self.dense2_enc(_h1))
    mu = self.dense_mu_enc(_h2)
    _logvar = self.dense_logvar_enc(_h2)
    logvar = torch.log(nn.functional.softplus(_logvar)+1e-8)
    return mu, logvar

  def decode(self, z):
    _h1 = self.relu(self.dense1_dec(z))
    _h2 = self.relu(self.dense2_dec(_h1))
    xhat = torch.sigmoid(self.dense3_dec(_h2))
    return xhat.reshape((-1, 1, self.dim_x_list[0], self.dim_x_list[1]))

  def reparam(self, mu, logvar):
    # reparameterization trick
    std = torch.exp(0.5 * logvar)
    eps = torch.randn_like(std)  # sampling epsilon
    z = mu + std*self.epsilon.sample(mu.shape)
    return z

  def forward(self, x):
    x = torch.flatten(x, start_dim=1)
    mu, logvar = self.encode(x)
    z = self.reparam(mu, logvar)
    xhat = self.decode(z)
    return xhat, mu, logvar

  @staticmethod
  def loss_function(x, xhat, mu, logvar):
    # Reconstruction loss
    recon_loss = nn.functional.binary_cross_entropy(xhat, x, reduction='sum')
    # recon_loss = ((x - xhat)**2).sum()
    # Regularization loss
    reg_loss = - 0.5 * torch.sum(1+ logvar - mu.pow(2) - logvar.exp())
    return recon_loss, reg_loss

"""### **Train the $\beta$-VAE Network**"""

dim_z = 2
dim_h = 256
epochs = 20
displaystep = 5
plotheight = 1.25
beta = 0.5
bvae = BVAE(dim_x=dim_x, dim_x_list=dim_x_list, dim_h=dim_h, dim_z=dim_z).to(device)

opt = torch.optim.Adam(bvae.parameters(), lr=1e-4)

reconloss_list, regloss_list = [], []
for epoch in range(epochs):
  reconloss, regloss = [], []
  for x, y in traindataloader:
    x = x.float().to(device)
    opt.zero_grad()
    _x_hat, _mu, _logvar = bvae(x)
    _recon_loss, _reg_loss = bvae.loss_function(x, _x_hat, _mu, _logvar)
    _recon_loss = beta * _recon_loss
    _bvae_loss = _recon_loss + _reg_loss
    _bvae_loss.backward()
    opt.step()
    reconloss.append(_recon_loss.item())
    regloss.append(_reg_loss.item())

  _recon_l_mean, _recon_l_std = np.mean(reconloss), np.std(reconloss)
  reconloss_list.append([_recon_l_mean, _recon_l_std])
  _reg_l_mean, _reg_l_std = np.mean(regloss), np.std(regloss)
  regloss_list.append([_reg_l_mean, _reg_l_std])

  if (epoch+1) % displaystep == 0 or (epoch+1) in [1]:
    print("{:4d} loss(recon): {:7.5f}/{:7.5f}, loss(reg): {:7.5f}/{:7.5f}".
          format(epoch+1,_recon_l_mean,_recon_l_std,_reg_l_mean,_reg_l_std))
    for xtest, ytest in testdataloader:
      xtest = xtest.float().to(device)
      xtest_sample, mutest, logvartest = bvae(xtest)
      xtest_recon = bvae.decode(mutest)
      xtest = xtest.detach().cpu().numpy()
      xtest_sample = xtest_sample.detach().cpu().numpy()
      xtest_recon = xtest_recon.detach().cpu().numpy()

      # Plot
      fig, axs = plt.subplots(ncols=nplot_test, nrows=3,
                              figsize=(plotheight * nplot_test, plotheight * 3))
      for axi, (dat, lab) in enumerate(zip([xtest, xtest_recon, xtest_sample],["$x$", "$\hat{x}_{recon}$", "$\hat{x}_{sample}$"],)):
        for ex in range(nplot_test):
          axs[axi, ex].matshow(dat[ex].squeeze(), vmin=0, vmax=1)
          axs[axi, ex].axes.get_xaxis().set_ticks([])
          axs[axi, ex].axes.get_yaxis().set_ticks([])
          axs[axi, 0].set_ylabel(lab, rotation=0, labelpad=20)
      plt.show()
      plt.close()
      break